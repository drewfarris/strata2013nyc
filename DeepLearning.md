# Deep Learning
1958 – Neural Network OriginNeural Networks are some of the oldest algorithms in AI – amazing quality of results.
Emipiral Result beating the prior art.  > “Instead of doing AI, we spend our lives doing curve fitting” - Andrew Ng
Automatic Feature engineering.Brief History of the Last 4 yearsNew Breakthrough results.### Case studies.- Speech Recognition at Google- Molecular Activity Prediction on Kaggle### History:
- Perceptron (1957)- Backpropagation (- Deep Neural Networks** Perceptron **- Single Neuron Model- Multiple inputs (each input has activation + weight)- Output is the weighted sum of all input activations.```XWH(x)```
Output of each layer of the network, input to next level of network. Neural Network can approximate any output.**Backpropagation (1974)** – tries to answMinimize squared error between the output at the last layer and labels from the training set using gradient descent.For hidden layers apply the chain rule recursively – Backpropigation of errors throughout earlier layers of the network. 
This technique peaked in the 80’s (Along with new wave hairdos)
PersistenceProblems
- Required labeled data – most is unlabeled- Easy to get stuck on poor local optima – this gets worse as you add more layers.- Slow to train due to the diffusion of gradients. – also worse with more layers.Earlier layers you train slowly. Moore’s law – tend to forgot how crappy computers were back then.Moore’s law + new algorithms**Deep Neural Networks**-	Unsupervised pre-training.>> If you want to do computer vision first learn computer graphics.>
- Add a pre-training phase to learn the structure of the input data- No labeled data- No bad local optima- A greedy layer-wise algorithm makes this efficient and fast- Search terms include “unsupervised feature learning “ “greedy layer-wise pretraining” “generative pretraining” “unsupervised pretraining”**RBM: Restricted Boltzman Machines**Given nodes per pixel, estimate the probability that a node will be 1.W shape.If you know the hidden units you can estimate the visible units. And vice versaSimple mathematic form.*Weird dirty hack*Contrastive Divergence: instead of an infinite chain of gibbs sampling, you do a single pass of Gibbs sampling. It is not maximizing the likelihood of the training data.Once you know how to train one RBM you can train a whole stack of RBM’s by stacking them.**Layering RBM’s**Greedy layer-wise pre-training. – Becomes a “Deep Belief Network” when Stacked References to original papers. Slides available.Visualization – generating of images based on Number Recognition Problem- Edge detection on layer one.- Learning a hierarchy of concepts that goes from most concrete to most abstract.- Unsupervised feature learning.- Descriminate Fine Tuning using Backprop.Visualization of model space. Projected into 2 dimensions for visualization. Deep Learning – Hessian free optimization using second deritaves.Don’t need second deratives if you tweak [What?]*Drop-out* is a way to address overfitting. For each training example, randomly remove half the nodes in each layer. Throw away half the nodes.When you don’t have drop out*So that was 2006-2010*- deep belief networks- fine tuning via backprop- sigmoid**Now in 2013**
- Highly divergent research- Unsupervised pretraining or modify optimization algo- Backprop? - Rectified linear units (Hessian Free optimization)- Dropout###Case Studies
##### Speech Recognition / Vision – RLU’s -> Fourier transform, cosine transform 
Used to be:  -> Fourier transfer -> DNN -> HMM -> Decision Tree -> Lexicon => Language Model#####Molecular Acitivty Prediction
- Predict interations between molecule
- Used in drug diacovery to identify sode effect- Winning tamed used DMMs with no feature engineeringVery Minimal preprocessing – log transform each indificual input feature / covariate.George Dahl, winning team didn't know much about the domain.## Take awayReal magic is in the feature engineering using Human Intelligence. Actuall machine algorithms doesn’t get you very far. However this is starting to change with DNN’s ### Question & Answers
L2 norm? If so, what happens if you need to Maximum Mutual Information. 